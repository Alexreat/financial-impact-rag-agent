{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69bf925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAG · M5.A: Retrieval sanity test ===\n",
      "Event days loaded: 145 rows. Looking for 2011-08-09… FOUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News rows: 887,221\n",
      "Date window (-2..+2): ['2011-08-07', '2011-08-08', '2011-08-09', '2011-08-10', '2011-08-11']\n",
      "CSV candidates in window: 383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved: 8 (top-8) in window 2011-08-07 .. 2011-08-11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>approx_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-08-09</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>Smartphones Drive U.S. Cellular 2Q - Analyst Blog</td>\n",
       "      <td>0.6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-08-09</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>StanCorp Financial (SFG) - Bear of the Day</td>\n",
       "      <td>0.7248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>webmaster</td>\n",
       "      <td>Nokia's U.S. N9 Plans; AOL Tanks</td>\n",
       "      <td>0.6158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>webmaster</td>\n",
       "      <td>5 Stocks to Watch: Bank of America, Cisco</td>\n",
       "      <td>0.7232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>webmaster</td>\n",
       "      <td>AOL Plans $250 Million Stock Buyback</td>\n",
       "      <td>0.6997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>TV on Tablets - A Reality - Analyst Blog</td>\n",
       "      <td>0.7083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>webmaster</td>\n",
       "      <td>AOL to Buy Back $250M in Stock</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>Activision Promotes PROTOTYPE 2 - Analyst Blog</td>\n",
       "      <td>0.7206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     source                                              title  \\\n",
       "0  2011-08-09      Zacks  Smartphones Drive U.S. Cellular 2Q - Analyst Blog   \n",
       "1  2011-08-09      Zacks         StanCorp Financial (SFG) - Bear of the Day   \n",
       "2  2011-08-10  webmaster                   Nokia's U.S. N9 Plans; AOL Tanks   \n",
       "3  2011-08-10  webmaster          5 Stocks to Watch: Bank of America, Cisco   \n",
       "4  2011-08-11  webmaster               AOL Plans $250 Million Stock Buyback   \n",
       "5  2011-08-11      Zacks           TV on Tablets - A Reality - Analyst Blog   \n",
       "6  2011-08-11  webmaster                     AOL to Buy Back $250M in Stock   \n",
       "7  2011-08-11      Zacks     Activision Promotes PROTOTYPE 2 - Analyst Blog   \n",
       "\n",
       "   approx_score  \n",
       "0        0.6950  \n",
       "1        0.7248  \n",
       "2        0.6158  \n",
       "3        0.7232  \n",
       "4        0.6997  \n",
       "5        0.7083  \n",
       "6        0.7200  \n",
       "7        0.7206  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Retrieval sanity test done. If this looks good, next we’ll wire this into the LLM JSON step.\n"
     ]
    }
   ],
   "source": [
    "# RAG  Retrieval sanity test for a single event date\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "\n",
    "print(\"=== RAG · M5.A: Retrieval sanity test ===\")\n",
    "\n",
    "# --- Inputs you can tweak ---\n",
    "TARGET_DATE = \"2011-08-09\"   # your event day\n",
    "WINDOW_DAYS = 2              # ±N window\n",
    "TOP_K = 8                    # how many items to retrieve\n",
    "QUERY_TEXT = \"Apple AAPL\"    # simple semantic query\n",
    "\n",
    "# --- Paths ---\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "INDEX_DIR = (DATA_DIR / \"chroma_index\" / \"why-move-v1\").resolve()\n",
    "COLLECTION_NAME = \"why-move-v1\"\n",
    "\n",
    "# --- Load event days (for info) ---\n",
    "ev_path = DATA_DIR / \"event_days.csv\"\n",
    "if ev_path.exists():\n",
    "    df_ev = pd.read_csv(ev_path)\n",
    "    print(f\"Event days loaded: {len(df_ev)} rows. Looking for {TARGET_DATE}…\",\n",
    "          \"FOUND\" if (df_ev.astype(str)[\"Date\"].str[:10] == TARGET_DATE).any() else \"not found in file\")\n",
    "else:\n",
    "    print(\"Note: event_days.csv not found — skipping this info check.\")\n",
    "\n",
    "# --- Load cleaned news ---\n",
    "news_path = DATA_DIR / \"news_clean.csv\"\n",
    "assert news_path.exists(), f\"Missing {news_path}\"\n",
    "df_news = pd.read_csv(news_path, dtype={\"date\":\"string\",\"title\":\"string\",\"source\":\"string\",\"doc_id\":\"string\"})\n",
    "print(f\"News rows: {len(df_news):,}\")\n",
    "\n",
    "# --- Build the date window list (YYYY-MM-DD strings) ---\n",
    "td = pd.to_datetime(TARGET_DATE)\n",
    "window = pd.date_range(td - pd.Timedelta(days=WINDOW_DAYS),\n",
    "                       td + pd.Timedelta(days=WINDOW_DAYS), freq=\"D\")\n",
    "window_str = window.strftime(\"%Y-%m-%d\").tolist()\n",
    "print(f\"Date window ({-WINDOW_DAYS}..+{WINDOW_DAYS}): {window_str}\")\n",
    "\n",
    "# --- Quick candidate count in CSV (sanity only) ---\n",
    "candidates = df_news[df_news[\"date\"].isin(window_str)]\n",
    "print(f\"CSV candidates in window: {len(candidates):,}\")\n",
    "\n",
    "# --- Connect to Chroma persistent collection ---\n",
    "client = chromadb.PersistentClient(path=str(INDEX_DIR))\n",
    "collection = client.get_or_create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    metadata={\"hnsw:space\": \"cosine\"},\n",
    ")\n",
    "\n",
    "# --- Query Chroma with a metadata filter on 'date' (within window) ---\n",
    "def do_query(window_list, k):\n",
    "    if len(window_list) == 0:\n",
    "        return None\n",
    "    return collection.query(\n",
    "        query_texts=[QUERY_TEXT],\n",
    "        n_results=min(k, 20),              # guard: don't request more than 20 at once\n",
    "        where={\"date\": {\"$in\": window_list}},\n",
    "    )\n",
    "\n",
    "res = do_query(window_str, TOP_K)\n",
    "\n",
    "# --- Fallbacks if nothing found in a tight window ---\n",
    "if not res or not res.get(\"ids\") or len(res[\"ids\"][0]) == 0:\n",
    "    print(\"0 candidates in ±2 days → widening to ±5…\")\n",
    "    window = pd.date_range(td - pd.Timedelta(days=5), td + pd.Timedelta(days=5), freq=\"D\")\n",
    "    window_str = window.strftime(\"%Y-%m-%d\").tolist()\n",
    "    res = do_query(window_str, TOP_K)\n",
    "\n",
    "if (not res) or (len(res.get(\"ids\", [[]])[0]) == 0):\n",
    "    print(\"Still 0 → widening to ±7…\")\n",
    "    window = pd.date_range(td - pd.Timedelta(days=7), td + pd.Timedelta(days=7), freq=\"D\")\n",
    "    window_str = window.strftime(\"%Y-%m-%d\").tolist()\n",
    "    res = do_query(window_str, TOP_K)\n",
    "\n",
    "# --- Pretty preview ---\n",
    "docs   = res.get(\"documents\", [[]])[0] if res else []\n",
    "metas  = res.get(\"metadatas\", [[]])[0] if res else []\n",
    "scores = res.get(\"distances\", [[]])[0] if res else []  # for cosine, lower is closer in Chroma's HNSW cosine space\n",
    "\n",
    "print(f\"\\nRetrieved: {len(docs)} (top-{TOP_K}) in window {window_str[0]} .. {window_str[-1]}\")\n",
    "if len(docs) == 0:\n",
    "    print(\"No results — try a larger window or different QUERY_TEXT.\")\n",
    "else:\n",
    "    # Build a tiny table\n",
    "    rows = []\n",
    "    for m, d, s in zip(metas, docs, scores):\n",
    "        rows.append({\n",
    "            \"date\": m.get(\"date\", \"\"),\n",
    "            \"source\": m.get(\"source\", \"\"),\n",
    "            \"title\": (d[:120] + \"…\") if len(d) > 120 else d,\n",
    "            \"approx_score\": round(float(s), 4) if isinstance(s, (int, float)) else s\n",
    "        })\n",
    "    df_prev = pd.DataFrame(rows).sort_values([\"date\",\"approx_score\"]).reset_index(drop=True)\n",
    "    display(df_prev)\n",
    "\n",
    "print(\"\\n Retrieval sanity test done. If this looks good, next we’ll wire this into the LLM JSON step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967cad0",
   "metadata": {},
   "source": [
    "### OpenAI API key chek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26fa03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key visible to Python? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Key visible to Python?\", \"OPENAI_API_KEY\" in os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e933d65",
   "metadata": {},
   "source": [
    "### First JSON answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67f0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Valid JSON from gpt-5-nano:\n",
      "{\n",
      "  \"date\": \"2011-08-09\",\n",
      "  \"ticker\": \"AAPL\",\n",
      "  \"explanation\": \"Insufficient context; no AAPL-specific drivers provided.\",\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"confidence\": 0.4,\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"title\": \"Zacks: Smartphones Drive U.S. Cellular 2Q - Analyst Blog\",\n",
      "      \"url\": \"\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# RAG · M6.A — gpt-5-nano via Responses API (no temperature)\n",
    "\n",
    "import os, json, re\n",
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field, ValidationError, constr, confloat\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Guards ---\n",
    "assert \"OPENAI_API_KEY\" in os.environ, \"Missing OPENAI_API_KEY\"\n",
    "assert 'df_prev' in globals(), \"Run the retrieval cell first to create df_prev.\"\n",
    "\n",
    "# --- Build compact context from retrieval preview ---\n",
    "context_items = df_prev.head(8).to_dict(orient=\"records\")\n",
    "context_str = \"\\n\".join(f\"- {r['date']} | {r['source']}: {r['title']}\" for r in context_items)\n",
    "\n",
    "# --- Pydantic v2 schema ---\n",
    "class Citation(BaseModel):\n",
    "    title: constr(min_length=2)\n",
    "    url: str = Field(default=\"\")\n",
    "\n",
    "class WhyMove(BaseModel):\n",
    "    date: constr(pattern=r\"\\d{4}-\\d{2}-\\d{2}\")\n",
    "    ticker: constr(min_length=1)\n",
    "    explanation: constr(min_length=10, max_length=120)\n",
    "    sentiment: Literal[\"positive\", \"neutral\", \"negative\"]\n",
    "    confidence: confloat(ge=0.0, le=1.0)\n",
    "    citations: List[Citation] = Field(min_length=1)\n",
    "\n",
    "# --- Instruction string for Responses API ---\n",
    "INSTRUCTION = f\"\"\"\n",
    "You are a careful financial analyst.\n",
    "\n",
    "Task:\n",
    "Return STRICT JSON answering: \"Why did AAPL move on 2011-08-09?\"\n",
    "\n",
    "Context (use ONLY this):\n",
    "{context_str}\n",
    "\n",
    "Rules:\n",
    "- If context is insufficient, say so briefly in the explanation.\n",
    "- explanation ≤ 120 chars, factual, non-speculative.\n",
    "- sentiment in {{positive|neutral|negative}}\n",
    "- confidence between 0 and 1.\n",
    "- citations: list with at least one item; each has \"title\" from the context; \"url\" can be empty.\n",
    "\n",
    "Return ONLY valid JSON with keys exactly:\n",
    "{{\n",
    "  \"date\": \"2011-08-09\",\n",
    "  \"ticker\": \"AAPL\",\n",
    "  \"explanation\": \"...\",\n",
    "  \"sentiment\": \"positive|neutral|negative\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"citations\": [{{\"title\":\"...\", \"url\":\"\"}}]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# --- Call Responses API (note: no temperature parameter) ---\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",   # free model\n",
    "    input=INSTRUCTION,\n",
    ")\n",
    "\n",
    "raw = resp.output_text.strip()\n",
    "\n",
    "# --- Try to parse JSON; if it failed, extract the first {...} block ---\n",
    "def coerce_json_text(text: str) -> str:\n",
    "    try:\n",
    "        json.loads(text)\n",
    "        return text\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "        return m.group(0).strip() if m else text\n",
    "\n",
    "raw_json = coerce_json_text(raw)\n",
    "\n",
    "# --- Validate with Pydantic ---\n",
    "try:\n",
    "    data = json.loads(raw_json)\n",
    "    parsed = WhyMove(**data)\n",
    "    print(\" Valid JSON from gpt-5-nano:\")\n",
    "    print(json.dumps(parsed.model_dump(), indent=2))\n",
    "except (json.JSONDecodeError, ValidationError) as e:\n",
    "    print(\"Invalid JSON. Error below; showing raw model output to debug.\")\n",
    "    print(e)\n",
    "    print(\"\\n--- RAW MODEL OUTPUT ---\\n\", raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da70e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (finance-rag)",
   "language": "python",
   "name": "finance-rag-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
