{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f002793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.10-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting langchain-core>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from langgraph) (2.8.2)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.11.0-cp311-cp311-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: anyio in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
      "Requirement already satisfied: certifi in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading langsmith-0.4.34-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (2.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/.venv/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Downloading langgraph-0.6.10-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n",
      "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.4.34-py3-none-any.whl (386 kB)\n",
      "Downloading ormsgpack-1.11.0-cp311-cp311-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (367 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading zstandard-0.25.0-cp311-cp311-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.6/640.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, xxhash, ormsgpack, jsonpatch, requests-toolbelt, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [langgraph]11\u001b[0m [langchain-core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed jsonpatch-1.33 langchain-core-0.3.79 langgraph-0.6.10 langgraph-checkpoint-2.1.2 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 langsmith-0.4.34 ormsgpack-1.11.0 requests-toolbelt-1.0.0 xxhash-3.6.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "LangGraph installed and libraries imported. Ready for next step!\n"
     ]
    }
   ],
   "source": [
    "# First, let's install the library\n",
    "%pip install langgraph\n",
    "\n",
    "# Now, import the basics we will need\n",
    "import os\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "print(\"LangGraph installed and libraries imported. Ready for next step!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef3350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key is ready.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OpenAI API key goes here\"\n",
    "\n",
    "\n",
    "# --- Check ---\n",
    "assert \"OPENAI_API_KEY\" in os.environ, \"Please set your OPENAI_API_KEY\"\n",
    "print(\"✅ API key is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce06750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "\n",
    "def retrieve_documents(target_date: str, query_text: str = \"Apple AAPL\", window_days: int = 2, top_k: int = 8) -> list:\n",
    "    \"\"\"\n",
    "    This function finds relevant news articles from the ChromaDB database for a specific date.\n",
    "    It takes a date as an ingredient and returns a list of documents as its finished dish.\n",
    "    \"\"\"\n",
    "    print(f\"--- Running Retriever for date: {target_date} ---\")\n",
    "\n",
    "    # --- Define file paths ---\n",
    "    DATA_DIR = Path(\"../data\").resolve()\n",
    "    INDEX_DIR = (DATA_DIR / \"chroma_index\" / \"why-move-v1\").resolve()\n",
    "    COLLECTION_NAME = \"why-move-v1\"\n",
    "\n",
    "    # --- Connect to the database ---\n",
    "    client = chromadb.PersistentClient(path=str(INDEX_DIR))\n",
    "    collection = client.get_collection(name=COLLECTION_NAME) # Use get_collection, assuming it exists\n",
    "\n",
    "    # --- Build the date window to search within ---\n",
    "    td = pd.to_datetime(target_date)\n",
    "    window = pd.date_range(td - pd.Timedelta(days=window_days),\n",
    "                           td + pd.Timedelta(days=window_days), freq=\"D\")\n",
    "    window_str = window.strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "    # --- Query the database with a filter for the date window ---\n",
    "    res = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=top_k,\n",
    "        where={\"date\": {\"$in\": window_str}},\n",
    "    )\n",
    "\n",
    "    # The \"documents\" key contains the list of news article texts we found.\n",
    "    documents = res.get(\"documents\", [[]])[0]\n",
    "\n",
    "    print(f\"Retrieved {len(documents)} documents.\")\n",
    "\n",
    "    # This is the \"finished dish\" that our function serves.\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4899f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 2: The Generator\n",
    "\n",
    "import json\n",
    "import re\n",
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field, ValidationError, constr, confloat\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Pydantic schema. It defines the structure of our desired JSON output. ---\n",
    "class Citation(BaseModel):\n",
    "    title: constr(min_length=2)\n",
    "    url: str = Field(default=\"\")\n",
    "\n",
    "class WhyMove(BaseModel):\n",
    "    date: constr(pattern=r\"\\d{4}-\\d{2}-\\d{2}\")\n",
    "    ticker: constr(min_length=1)\n",
    "    explanation: constr(min_length=10, max_length=120)\n",
    "    sentiment: Literal[\"positive\", \"neutral\", \"negative\"]\n",
    "    confidence: confloat(ge=0.0, le=1.0)\n",
    "    citations: List[Citation] = Field(min_length=1)\n",
    "\n",
    "\n",
    "def generate_answer(retrieved_docs: list, target_date: str, ticker: str = \"AAPL\") -> dict:\n",
    "    \"\"\"\n",
    "    This function takes a list of documents and generates a structured JSON answer using an AI model.\n",
    "    Its ingredients are the documents from the Retriever, and its dish is the final, validated answer.\n",
    "    \"\"\"\n",
    "    print(\"--- Running Generator ---\")\n",
    "\n",
    "    # --- If no documents were found, return a default \"insufficient context\" message ---\n",
    "    if not retrieved_docs:\n",
    "        print(\"Generator received no documents. Returning default answer.\")\n",
    "        default_explanation = {\n",
    "            \"date\": target_date,\n",
    "            \"ticker\": ticker,\n",
    "            \"explanation\": \"Insufficient context; no documents were found to analyze.\",\n",
    "            \"sentiment\": \"neutral\",\n",
    "            \"confidence\": 0.1,\n",
    "            \"citations\": [{\"title\": \"No documents found\", \"url\": \"\"}],\n",
    "        }\n",
    "        return default_explanation\n",
    "\n",
    "    # --- Build the context string from the documents ---\n",
    "    context_str = \"\\n\".join(f\"- {doc}\" for doc in retrieved_docs)\n",
    "\n",
    "    # --- Create the prompt for the AI ---\n",
    "    prompt = f\"\"\"\n",
    "    You are a careful financial analyst. Your task is to return STRICT JSON answering: \"Why did {ticker} move on {target_date}?\"\n",
    "    Use ONLY the following context:\n",
    "    {context_str}\n",
    "\n",
    "    Rules:\n",
    "    - If context is insufficient, say so briefly in the explanation.\n",
    "    - The explanation must be 120 characters or less.\n",
    "    - sentiment must be one of: \"positive\", \"neutral\", or \"negative\".\n",
    "    - confidence is a score from 0.0 to 1.0.\n",
    "    - The citations list must have at least one item. You can use the document text as the \"title\".\n",
    "\n",
    "    Return ONLY a valid JSON object matching this schema:\n",
    "    {{\n",
    "      \"date\": \"{target_date}\",\n",
    "      \"ticker\": \"{ticker}\",\n",
    "      \"explanation\": \"...\",\n",
    "      \"sentiment\": \"...\",\n",
    "      \"confidence\": 0.0,\n",
    "      \"citations\": [{{\"title\":\"...\", \"url\":\"\"}}]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Call the AI model ---\n",
    "    client = OpenAI()\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", # Using a more modern and reliable model\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    raw_json_output = resp.choices[0].message.content\n",
    "\n",
    "    # --- Validate the output with our Pydantic schema ---\n",
    "    try:\n",
    "        parsed_output = WhyMove.model_validate_json(raw_json_output)\n",
    "        print(\"Generator successfully created a valid answer.\")\n",
    "        return parsed_output.model_dump()\n",
    "    except ValidationError as e:\n",
    "        print(f\"ERROR: AI returned invalid JSON. Error: {e}\")\n",
    "        # In case of an error, we return a structured error message\n",
    "        error_explanation = {\n",
    "            \"date\": target_date,\n",
    "            \"ticker\": ticker,\n",
    "            \"explanation\": \"Error: The AI model returned a malformed response.\",\n",
    "            \"sentiment\": \"neutral\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"citations\": [{\"title\": \"Malformed AI response\", \"url\": \"\"}],\n",
    "        }\n",
    "        return error_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a0e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 - DESIGNING THE AGENT\n",
    "# Action 2.1: Define the Agent's Memory (the \"State\")\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The original question, the date we are asking about.\n",
    "    target_date: str\n",
    "\n",
    "    # A list to hold the news articles our retriever finds.\n",
    "    retrieved_docs: list\n",
    "\n",
    "    # A dictionary to hold the final JSON answer from the generator.\n",
    "    generation: dict\n",
    "        # NEW: Add a counter for retries\n",
    "    retries: int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a503f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action 2.2: Define the Agent's Jobs (the \"Nodes\")\n",
    "\n",
    "# This is the first job: retrieving documents.\n",
    "# UPGRADE to the retrieve_node\n",
    "def retrieve_node(state: AgentState) -> dict:\n",
    "    print(\"--- Node: RETRIEVE ---\")\n",
    "    # NEW: Increment the retry counter each time this node is run.\n",
    "    retries = state.get(\"retries\", 0) + 1 \n",
    "\n",
    "    target_date = state[\"target_date\"]\n",
    "    documents = retrieve_documents(target_date)\n",
    "\n",
    "    # Write both the documents and the new retry count back to the clipboard.\n",
    "    return {\"retrieved_docs\": documents, \"retries\": retries}\n",
    "\n",
    "# This is the second job: generating the answer.\n",
    "def generate_node(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    This node calls our generator tool.\n",
    "    It reads the documents from the state, runs the generator,\n",
    "    and writes the final JSON answer back to the state.\n",
    "    \"\"\"\n",
    "    print(\"--- Node: GENERATE ---\")\n",
    "    # Get the ingredients from the state's clipboard.\n",
    "    target_date = state[\"target_date\"]\n",
    "    retrieved_docs = state[\"retrieved_docs\"]\n",
    "\n",
    "    # Run our \"toolbox\" function from Step 1.\n",
    "    generation = generate_answer(retrieved_docs, target_date)\n",
    "\n",
    "    # Write the final dish back to the clipboard.\n",
    "    return {\"generation\": generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f281989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the third job: critiquing the answer.\n",
    "def critique_node(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    This node checks the answer generated in the previous step.\n",
    "    It looks for keywords that suggest the answer is not good.\n",
    "    For now, it just prints its finding. It doesn't return anything.\n",
    "    \"\"\"\n",
    "    print(\"--- Node: CRITIQUE ---\")\n",
    "    # Get the generated answer from the clipboard.\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # Check if the explanation contains \"insufficient\" or \"error\".\n",
    "    if \"insufficient\" in generation[\"explanation\"].lower() or \"error\" in generation[\"explanation\"].lower():\n",
    "        # If it does, we consider the answer to be bad.\n",
    "        print(\"Critique: Generation is not acceptable. Needs a retry.\")\n",
    "    else:\n",
    "        # Otherwise, the answer looks good.\n",
    "        print(\"Critique: Generation looks good.\")\n",
    "\n",
    "    # This node doesn't need to change the state, so we return an empty dictionary.\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84733642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - CONNECTING THE DOTS\n",
    "# Action 3.1: Create the Whiteboard (Initialize the Graph)\n",
    "\n",
    "# We create an instance of the StateGraph class.\n",
    "# We pass it our AgentState blueprint to tell it how to structure its memory.\n",
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f391626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x30b122010>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action 3.2: Add the Jobs to the Whiteboard (Add the Nodes)\n",
    "\n",
    "# We add each job (node) to our workflow.\n",
    "# We give each node a simple name (a string) and tell it which function to run for that job.\n",
    "workflow.add_node(\"retrieve\", retrieve_node)\n",
    "workflow.add_node(\"generate\", generate_node)\n",
    "workflow.add_node(\"critique\", critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b760935c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x30b122010>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action 3.3: Draw the Arrows (Add the Edges)\n",
    "\n",
    "# First, the simple arrows.\n",
    "# After \"retrieve\", it should always go to \"generate\".\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "# After \"generate\", it should always go to \"critique\".\n",
    "workflow.add_edge(\"generate\", \"critique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87793531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our \"traffic controller\" function.\n",
    "# UPGRADE to the decision logic\n",
    "def decide_to_finish_or_retry(state: AgentState) -> str:\n",
    "    print(\"--- Node: DECIDE ---\")\n",
    "    generation = state[\"generation\"]\n",
    "    retries = state[\"retries\"]\n",
    "\n",
    "    # NEW: Check the retry counter first.\n",
    "    if retries > 2:\n",
    "        print(f\"Decision: Reached max retries ({retries}). Finishing.\")\n",
    "        return \"finish\"\n",
    "\n",
    "    if \"insufficient\" in generation[\"explanation\"].lower() or \"error\" in generation[\"explanation\"].lower():\n",
    "        print(f\"Decision: Answer not good. Retrying (attempt {retries}).\")\n",
    "        return \"retry\"\n",
    "    else:\n",
    "        print(\"Decision: Answer is good. Finishing.\")\n",
    "        return \"finish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca0215bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x30b122010>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we add the special conditional arrow to the workflow.\n",
    "workflow.add_conditional_edges(\n",
    "    # The starting point of the decision is the \"critique\" node.\n",
    "    \"critique\",\n",
    "    # The function that makes the decision is our \"traffic controller\".\n",
    "    decide_to_finish_or_retry,\n",
    "    # This is the \"map\" that tells the agent where to go based on the decision.\n",
    "    {\n",
    "        \"retry\": \"retrieve\", # If the decision is \"retry\", go back to the \"retrieve\" job.\n",
    "        \"finish\": END,       # If the decision is \"finish\", end the entire process.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "061c57c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x30b122010>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action 3.4: Set the Start Line\n",
    "\n",
    "# We tell our workflow that the \"retrieve\" node is always the first step.\n",
    "workflow.set_entry_point(\"retrieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "081153c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent workflow compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# STEP 4 - BUILD AND RUN\n",
    "# Action 4.2: Compile the workflow into a runnable app\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"Agent workflow compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6353c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Node: RETRIEVE ---\n",
      "--- Running Retriever for date: 2011-08-09 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 8 documents.\n",
      "--- Event: Node 'retrieve' Finished ---\n",
      "{'retrieved_docs': [\"Nokia's U.S. N9 Plans; AOL Tanks\", 'Smartphones Drive U.S. Cellular 2Q - Analyst Blog', 'AOL Plans $250 Million Stock Buyback', 'TV on Tablets - A Reality - Analyst Blog', 'AOL to Buy Back $250M in Stock', 'Activision Promotes PROTOTYPE 2 - Analyst Blog', '5 Stocks to Watch: Bank of America, Cisco', 'StanCorp Financial (SFG) - Bear of the Day'], 'retries': 1}\n",
      "\n",
      "\n",
      "--- Node: GENERATE ---\n",
      "--- Running Generator ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator successfully created a valid answer.\n",
      "--- Event: Node 'generate' Finished ---\n",
      "{'generation': {'date': '2011-08-09', 'ticker': 'AAPL', 'explanation': 'Insufficient context to determine reasons for AAPL movement.', 'sentiment': 'neutral', 'confidence': 0.2, 'citations': [{'title': \"Nokia's U.S. N9 Plans; AOL Tanks\", 'url': ''}]}}\n",
      "\n",
      "\n",
      "--- Node: CRITIQUE ---\n",
      "Critique: Generation is not acceptable. Needs a retry.\n",
      "--- Node: DECIDE ---\n",
      "Decision: Answer not good. Retrying (attempt 1).\n",
      "--- Event: Node 'critique' Finished ---\n",
      "None\n",
      "\n",
      "\n",
      "--- Node: RETRIEVE ---\n",
      "--- Running Retriever for date: 2011-08-09 ---\n",
      "Retrieved 8 documents.\n",
      "--- Event: Node 'retrieve' Finished ---\n",
      "{'retrieved_docs': [\"Nokia's U.S. N9 Plans; AOL Tanks\", 'Smartphones Drive U.S. Cellular 2Q - Analyst Blog', 'AOL Plans $250 Million Stock Buyback', 'TV on Tablets - A Reality - Analyst Blog', 'AOL to Buy Back $250M in Stock', 'Activision Promotes PROTOTYPE 2 - Analyst Blog', '5 Stocks to Watch: Bank of America, Cisco', 'StanCorp Financial (SFG) - Bear of the Day'], 'retries': 2}\n",
      "\n",
      "\n",
      "--- Node: GENERATE ---\n",
      "--- Running Generator ---\n",
      "Generator successfully created a valid answer.\n",
      "--- Event: Node 'generate' Finished ---\n",
      "{'generation': {'date': '2011-08-09', 'ticker': 'AAPL', 'explanation': \"Context lacks information on AAPL's specific movements on this date.\", 'sentiment': 'neutral', 'confidence': 0.2, 'citations': [{'title': 'AOL Plans $250 Million Stock Buyback', 'url': ''}]}}\n",
      "\n",
      "\n",
      "--- Node: CRITIQUE ---\n",
      "Critique: Generation looks good.\n",
      "--- Node: DECIDE ---\n",
      "Decision: Answer is good. Finishing.\n",
      "--- Event: Node 'critique' Finished ---\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Action 4.3: Run the agent and stream the events\n",
    "\n",
    "# This is the initial \"clipboard\" we give the agent. \n",
    "# It only contains the question we want to ask.\n",
    "inputs = {\n",
    "    \"target_date\": \"2011-08-09\"\n",
    "}\n",
    "\n",
    "# We run the app by streaming its events.\n",
    "# This lets us see the output of each node as it runs.\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        # Print the name of the node that just ran\n",
    "        print(f\"--- Event: Node '{key}' Finished ---\")\n",
    "        # Print the content of the agent's clipboard (the state)\n",
    "        print(value)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5e422f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Node: RETRIEVE ---\n",
      "--- Running Retriever for date: 2011-10-05 ---\n",
      "Retrieved 8 documents.\n",
      "--- Event: Node 'retrieve' Finished ---\n",
      "{'retrieved_docs': [\"They Just Don't Get Apple!\", \"'Mad Money Lightning Round': Hold on Apple\", '6 Stocks to Watch: Apple, Yahoo!', \"Analysts' Actions: AAPL, NFLX, HD, VZ, S\", 'Nuance Acquires Swype; iPhone 4S Pre-Orders Begin', 'Philips Electronics NV - ADR (PHG) - Bear of the Day', 'Netflix, AOL: Tech Winners & Losers', 'A Bright Stock in Display Technology'], 'retries': 1}\n",
      "\n",
      "\n",
      "--- Node: GENERATE ---\n",
      "--- Running Generator ---\n",
      "Generator successfully created a valid answer.\n",
      "--- Event: Node 'generate' Finished ---\n",
      "{'generation': {'date': '2011-10-05', 'ticker': 'AAPL', 'explanation': \"Context does not provide specific reasons for AAPL's movement on this date.\", 'sentiment': 'neutral', 'confidence': 0.2, 'citations': [{'title': \"They Just Don't Get Apple!\", 'url': ''}]}}\n",
      "\n",
      "\n",
      "--- Node: CRITIQUE ---\n",
      "Critique: Generation looks good.\n",
      "--- Node: DECIDE ---\n",
      "Decision: Answer is good. Finishing.\n",
      "--- Event: Node 'critique' Finished ---\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The Final Test\n",
    "\n",
    "inputs = {\n",
    "    \"target_date\": \"2011-10-05\"  # The day Steve Jobs passed away, a major news event for Apple.\n",
    "}\n",
    "\n",
    "# Run the app again with this new date\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        print(f\"--- Event: Node '{key}' Finished ---\")\n",
    "        print(value)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b33ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (finance-rag)",
   "language": "python",
   "name": "finance-rag-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
