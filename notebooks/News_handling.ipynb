{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf59017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff2f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook location\n",
    "DATA_DIR = Path(\"../data\").resolve()  \n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef950f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# News file\n",
    "NEWS_PATH = \"hf://datasets/ashraq/financial-news/data/train-00000-of-00001-8ec327f23bbe0948.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d40d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Setup ===\n",
      "DATA_DIR : /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/data\n",
      "NEWS_PATH: hf://datasets/ashraq/financial-news/data/train-00000-of-00001-8ec327f23bbe0948.parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Setup ===\")\n",
    "print(f\"DATA_DIR : {DATA_DIR}\")\n",
    "print(f\"NEWS_PATH: {NEWS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bfd34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading raw news parquet ===\n",
      "Trying: pd.read_parquet(NEWS_PATH)\n",
      "\n",
      "=== Load OK ===\n",
      "Rows: 1,845,559  |  Columns: 5\n",
      "Columns: ['headline', 'url', 'publisher', 'date', 'stock']\n",
      "\n",
      "First 5 rows (raw):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
       "      <td>http://www.gurufocus.com/news/1153187/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>http://www.zacks.com/stock/news/931205/agilent...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-18 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138923/jp-morga...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138704/pershing...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1134012/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-12 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Agilent Technologies Announces Pricing of $5……...   \n",
       "1  Agilent (A) Gears Up for Q2 Earnings: What's i...   \n",
       "2  J.P. Morgan Asset Management Announces Liquida...   \n",
       "3  Pershing Square Capital Management, L.P. Buys ...   \n",
       "4  Agilent Awards Trilogy Sciences with a Golden ...   \n",
       "\n",
       "                                                 url  publisher  \\\n",
       "0  http://www.gurufocus.com/news/1153187/agilent-...  GuruFocus   \n",
       "1  http://www.zacks.com/stock/news/931205/agilent...      Zacks   \n",
       "2  http://www.gurufocus.com/news/1138923/jp-morga...  GuruFocus   \n",
       "3  http://www.gurufocus.com/news/1138704/pershing...  GuruFocus   \n",
       "4  http://www.gurufocus.com/news/1134012/agilent-...  GuruFocus   \n",
       "\n",
       "                  date stock  \n",
       "0  2020-06-01 00:00:00     A  \n",
       "1  2020-05-18 00:00:00     A  \n",
       "2  2020-05-15 00:00:00     A  \n",
       "3  2020-05-15 00:00:00     A  \n",
       "4  2020-05-12 00:00:00     A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random 3 rows (raw):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>948540</th>\n",
       "      <td>KMG Chemicals' (KMG) CEO Chris Fraser on Q1 20...</td>\n",
       "      <td>http://seekingalpha.com/article/3748906-kmg-ch...</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>2015-12-10 00:00:00</td>\n",
       "      <td>KMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769643</th>\n",
       "      <td>90 Champions, Contenders And Challengers Are D...</td>\n",
       "      <td>https://seekingalpha.com/article/4219769-90-ch...</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>2018-11-08 00:00:00</td>\n",
       "      <td>HEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195804</th>\n",
       "      <td>Pabrai Funds Portfolio Review: POT, BPO, BIP, ...</td>\n",
       "      <td>http://www.gurufocus.com/news/148936/pabrai-fu...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2011-10-21 00:00:00</td>\n",
       "      <td>BIP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline  \\\n",
       "948540  KMG Chemicals' (KMG) CEO Chris Fraser on Q1 20...   \n",
       "769643  90 Champions, Contenders And Challengers Are D...   \n",
       "195804  Pabrai Funds Portfolio Review: POT, BPO, BIP, ...   \n",
       "\n",
       "                                                      url      publisher  \\\n",
       "948540  http://seekingalpha.com/article/3748906-kmg-ch...  Seeking Alpha   \n",
       "769643  https://seekingalpha.com/article/4219769-90-ch...  Seeking Alpha   \n",
       "195804  http://www.gurufocus.com/news/148936/pabrai-fu...      GuruFocus   \n",
       "\n",
       "                       date stock  \n",
       "948540  2015-12-10 00:00:00   KMG  \n",
       "769643  2018-11-08 00:00:00   HEP  \n",
       "195804  2011-10-21 00:00:00   BIP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: We haven't changed any column names yet. This is the dataset as-is.\n"
     ]
    }
   ],
   "source": [
    "# Load the parquet file and preview\n",
    "\n",
    "print(\"=== Loading raw news parquet ===\")\n",
    "print(\"Trying: pd.read_parquet(NEWS_PATH)\")\n",
    "\n",
    "try:\n",
    "    df_raw = pd.read_parquet(NEWS_PATH)\n",
    "except Exception as e:\n",
    "    print(\"\\n[ERROR] Could not read the parquet file.\")\n",
    "    print(\"Tip: If the error mentions 'pyarrow', install it:  pip install pyarrow\")\n",
    "    print(\"Full error:\\n\", e)\n",
    "    raise\n",
    "\n",
    "print(\"\\n=== Load OK ===\")\n",
    "print(f\"Rows: {len(df_raw):,}  |  Columns: {len(df_raw.columns)}\")\n",
    "print(\"Columns:\", list(df_raw.columns))\n",
    "\n",
    "print(\"\\nFirst 5 rows (raw):\")\n",
    "display(df_raw.head(5))\n",
    "\n",
    "print(\"\\nRandom 3 rows (raw):\")\n",
    "display(df_raw.sample(3, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf96a69",
   "metadata": {},
   "source": [
    "### Mapping text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c867e19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Minimal schema mapping ===\n",
      "Columns before: ['headline', 'url', 'publisher', 'date', 'stock']\n",
      "Columns after normalize: ['headline', 'url', 'publisher', 'date', 'stock']\n",
      "\n",
      "Preview (5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-18 00:00:00</td>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>Zacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-12 00:00:00</td>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                              title  \\\n",
       "0  2020-06-01 00:00:00  Agilent Technologies Announces Pricing of $5……...   \n",
       "1  2020-05-18 00:00:00  Agilent (A) Gears Up for Q2 Earnings: What's i...   \n",
       "2  2020-05-15 00:00:00  J.P. Morgan Asset Management Announces Liquida...   \n",
       "3  2020-05-15 00:00:00  Pershing Square Capital Management, L.P. Buys ...   \n",
       "4  2020-05-12 00:00:00  Agilent Awards Trilogy Sciences with a Golden ...   \n",
       "\n",
       "      source  \n",
       "0  GuruFocus  \n",
       "1      Zacks  \n",
       "2  GuruFocus  \n",
       "3  GuruFocus  \n",
       "4  GuruFocus  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-null counts:\n",
      "date      1845559\n",
      "title     1845559\n",
      "source    1845559\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Keep only headline, publisher, date\n",
    "# Map to: title, source, date\n",
    "\n",
    "print(\"=== Minimal schema mapping ===\")\n",
    "print(\"Columns before:\", list(df_raw.columns))\n",
    "\n",
    "# Normalize column names\n",
    "df_tmp = df_raw.copy()\n",
    "df_tmp.columns = [c.strip().lower().replace(\" \", \"_\") for c in df_tmp.columns]\n",
    "\n",
    "print(\"Columns after normalize:\", list(df_tmp.columns))\n",
    "\n",
    "# Map only what we care about\n",
    "rename_map = {\n",
    "    \"headline\": \"title\",\n",
    "    \"publisher\": \"source\",\n",
    "    \"date\": \"date\"\n",
    "}\n",
    "df_tmp = df_tmp.rename(columns=rename_map)\n",
    "\n",
    "# Keep subset\n",
    "df_std = df_tmp[[\"date\", \"title\", \"source\"]].copy()\n",
    "\n",
    "print(\"\\nPreview (5 rows):\")\n",
    "display(df_std.head(5))\n",
    "\n",
    "print(\"\\nNon-null counts:\")\n",
    "print(df_std.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b0c16e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step B1: date parsing ===\n",
      "\n",
      "Raw date examples (as loaded):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-12 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date\n",
       "0  2020-06-01 00:00:00\n",
       "1  2020-05-18 00:00:00\n",
       "2  2020-05-15 00:00:00\n",
       "3  2020-05-15 00:00:00\n",
       "4  2020-05-12 00:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed to datetime. Null after parsing: 0 / 1,845,559\n",
      "Dropped rows with invalid dates: 0\n",
      "Remaining rows: 1,845,559\n",
      "\n",
      "Preview after cleaning (5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>Zacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title     source\n",
       "0  2020-06-01  Agilent Technologies Announces Pricing of $5……...  GuruFocus\n",
       "1  2020-05-18  Agilent (A) Gears Up for Q2 Earnings: What's i...      Zacks\n",
       "2  2020-05-15  J.P. Morgan Asset Management Announces Liquida...  GuruFocus\n",
       "3  2020-05-15  Pershing Square Capital Management, L.P. Buys ...  GuruFocus\n",
       "4  2020-05-12  Agilent Awards Trilogy Sciences with a Golden ...  GuruFocus"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse and clean 'date' column to ISO YYYY-MM-DD (string)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== Step B1: date parsing ===\")\n",
    "\n",
    "# Quick peek at raw values\n",
    "print(\"\\nRaw date examples (as loaded):\")\n",
    "display(df_std[\"date\"].head(5).to_frame())\n",
    "\n",
    "before_rows = len(df_std)\n",
    "\n",
    "# Parse with coercion (bad/messy -> NaT)\n",
    "parsed = pd.to_datetime(df_std[\"date\"], errors=\"coerce\", utc=False)\n",
    "\n",
    "# Report parsing issues\n",
    "num_null = parsed.isna().sum()\n",
    "print(f\"\\nParsed to datetime. Null after parsing: {num_null:,} / {before_rows:,}\")\n",
    "\n",
    "# Drop null dates (cannot proceed without a date)\n",
    "df_dates = df_std.loc[~parsed.isna()].copy()\n",
    "df_dates.loc[:, \"date\"] = parsed.loc[~parsed.isna()].dt.date.astype(str)  # ISO 'YYYY-MM-DD'\n",
    "\n",
    "after_rows = len(df_dates)\n",
    "dropped = before_rows - after_rows\n",
    "print(f\"Dropped rows with invalid dates: {dropped:,}\")\n",
    "print(f\"Remaining rows: {after_rows:,}\")\n",
    "\n",
    "# Sanity preview\n",
    "print(\"\\nPreview after cleaning (5 rows):\")\n",
    "display(df_dates.head(5))\n",
    "\n",
    "# Tiny assertions\n",
    "assert \"date\" in df_dates.columns, \"Date column missing after cleaning.\"\n",
    "assert df_dates[\"date\"].notnull().all(), \"Found null dates after cleaning.\"\n",
    "\n",
    "# Keep this cleaned frame for next steps\n",
    "df_clean_dates = df_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd102ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step B2: cleaning title/source and deduplicating ===\n",
      "Dropped rows with null title/source: 0\n",
      "Dropped exact duplicate rows: 958,338\n",
      "Dropped duplicate (date,title,source): 0\n",
      "\n",
      "Remaining rows: 887,221\n",
      "\n",
      "Preview after cleaning (5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>Zacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title     source\n",
       "0  2020-06-01  Agilent Technologies Announces Pricing of $5……...  GuruFocus\n",
       "1  2020-05-18  Agilent (A) Gears Up for Q2 Earnings: What's i...      Zacks\n",
       "2  2020-05-15  J.P. Morgan Asset Management Announces Liquida...  GuruFocus\n",
       "3  2020-05-15  Pershing Square Capital Management, L.P. Buys ...  GuruFocus\n",
       "4  2020-05-12  Agilent Awards Trilogy Sciences with a Golden ...  GuruFocus"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Drop empty title/source and remove duplicates\n",
    "\n",
    "print(\"=== Step B2: cleaning title/source and deduplicating ===\")\n",
    "\n",
    "before = len(df_clean_dates)\n",
    "\n",
    "# Drop rows with missing title or source\n",
    "df_nonnull = df_clean_dates.dropna(subset=[\"title\", \"source\"]).copy()\n",
    "after_nonnull = len(df_nonnull)\n",
    "print(f\"Dropped rows with null title/source: {before - after_nonnull:,}\")\n",
    "\n",
    "# Remove duplicates\n",
    "# First by exact duplicate rows\n",
    "df_dedup = df_nonnull.drop_duplicates()\n",
    "after_dedup1 = len(df_dedup)\n",
    "print(f\"Dropped exact duplicate rows: {after_nonnull - after_dedup1:,}\")\n",
    "\n",
    "# Then by (date + title + source)\n",
    "df_dedup = df_dedup.drop_duplicates(subset=[\"date\", \"title\", \"source\"])\n",
    "after_dedup2 = len(df_dedup)\n",
    "print(f\"Dropped duplicate (date,title,source): {after_dedup1 - after_dedup2:,}\")\n",
    "\n",
    "print(f\"\\nRemaining rows: {after_dedup2:,}\")\n",
    "\n",
    "# Sanity preview\n",
    "print(\"\\nPreview after cleaning (5 rows):\")\n",
    "display(df_dedup.head(5))\n",
    "\n",
    "# Keep cleaned frame for next step\n",
    "df_clean_news = df_dedup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3d5f0",
   "metadata": {},
   "source": [
    "### Saving data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef5005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Saving cleaned news ===\n",
      "Saved: /Users/valentinreateguirangel/Documents/MSc Machine Learning/Finance_RAG_why_move/finance-rag-why-move/data/news_clean.csv\n",
      "Total rows saved: 887,221\n",
      "\n",
      "Preview (5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>news_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>news_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>news_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>news_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>news_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title     source  \\\n",
       "0  2020-06-01  Agilent Technologies Announces Pricing of $5……...  GuruFocus   \n",
       "1  2020-05-18  Agilent (A) Gears Up for Q2 Earnings: What's i...      Zacks   \n",
       "2  2020-05-15  J.P. Morgan Asset Management Announces Liquida...  GuruFocus   \n",
       "3  2020-05-15  Pershing Square Capital Management, L.P. Buys ...  GuruFocus   \n",
       "4  2020-05-12  Agilent Awards Trilogy Sciences with a Golden ...  GuruFocus   \n",
       "\n",
       "   doc_id  \n",
       "0  news_0  \n",
       "1  news_1  \n",
       "2  news_2  \n",
       "3  news_3  \n",
       "4  news_4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save cleaned news to CSV (no chunking)\n",
    "print(\"=== Saving cleaned news ===\")\n",
    "\n",
    "DATA_DIR = Path(\"../data\").resolve()\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# add simple unique doc_id\n",
    "df_to_save = df_clean_news.copy()\n",
    "df_to_save = df_to_save.reset_index(drop=True)\n",
    "df_to_save[\"doc_id\"] = [\"news_\" + str(i) for i in df_to_save.index]\n",
    "\n",
    "# save\n",
    "out_path = DATA_DIR / \"news_clean.csv\"\n",
    "df_to_save.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved: {out_path}\")\n",
    "print(f\"Total rows saved: {len(df_to_save):,}\")\n",
    "\n",
    "print(\"\\nPreview (5 rows):\")\n",
    "display(df_to_save.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2595047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (finance-rag)",
   "language": "python",
   "name": "finance-rag-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
